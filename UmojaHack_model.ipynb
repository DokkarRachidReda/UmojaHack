{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UmojaHack_model.ipynb","provenance":[{"file_id":"1bVsPBs8XPqYmDN04XpanDrHFb6BcgvUv","timestamp":1588788305663},{"file_id":"1tJI37t3XoYDI-ZK9xeJ90v3NprsYQsfW","timestamp":1584792280675},{"file_id":"1XGyj42pVWQHkgqnKRVQZosQj81D-JEVP","timestamp":1584786982721}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9owHpJecwq7g","colab_type":"text"},"source":["# **The steps for the proposed solution**\n","1. Read the train and test data as a csv file\n","2. Check for null values\n","3. Adding new features \n","4. Data visualisaion\n","5. Features selection\n","6. Scale data\n","7. Encode data\n","8. Creating and Training the models\n","9. Make the preditions\n","10. Make the ouput file\n"]},{"cell_type":"markdown","metadata":{"id":"xKcJuq7bxof_","colab_type":"text"},"source":["# **1. Read the train and test data as a csv file**\n","Load the data for the competition."]},{"cell_type":"code","metadata":{"id":"OjrWXlEHVvpF","colab_type":"code","colab":{}},"source":["from zipfile import ZipFile\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpLIeb6wrN2h","colab_type":"code","colab":{}},"source":["# get the data from google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWBxvUr7rQ6Q","colab_type":"code","colab":{}},"source":["#container folder with project files\n","path = '/content/drive/My Drive/UmojaHack Datasets'\n","\n","# path to the challenge files \n","data_path = path + '/UmojaHack#3:Hotspots.zip'\n","password = 'e78sy8'     # password to unlock the data\n","\n","\n","with ZipFile(data_path, 'r') as zip:\n","  zip.printdir()\n","  print(\"Extracting all files...\")\n","  zip.extractall(pwd = bytes(password, 'utf-8'))\n","  print(\"Done extraction...\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2lLzfdilxfsY","colab_type":"code","colab":{}},"source":["# import the needed libraries\n","import pandas as pd\n","from sklearn.linear_model import RidgeCV\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","from sklearn import svm\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn import linear_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uaQM7lJHxRoe","colab_type":"code","colab":{}},"source":["train = pd.read_csv('UmojaHack#3:Hotspots/train.csv', parse_dates=['date'])\n","train.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RHksNuWBxeDn","colab_type":"code","colab":{}},"source":["test = pd.read_csv('UmojaHack#3:Hotspots/test.csv', parse_dates=['date'])\n","test.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"44BOGXo1PNjr","colab_type":"text"},"source":["# **2. Check for null values**\n"]},{"cell_type":"code","metadata":{"id":"SCnoWP0ByKPX","colab_type":"code","colab":{}},"source":["for col in train.columns:\n","  print(col,\"total null = \", train[col].isnull().sum(), \"total = \", len(set(train[col])))\n","print(train.columns)\n","total_areas = 3821"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xXIk62X9iONj","colab_type":"text"},"source":["# **3. Adding new features**\n"]},{"cell_type":"code","metadata":{"id":"bag8HJpxCucw","colab_type":"code","colab":{}},"source":["# Date variables\n","train['month'] = train.date.dt.month\n","test['month'] = test.date.dt.month"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0FXD7aXwPzjK","colab_type":"text"},"source":["# **4. Data visualisaion**\n","\n"]},{"cell_type":"code","metadata":{"id":"gK900PdVP0uw","colab_type":"code","colab":{}},"source":["# Plotting mean burn_area for each month - very strong mid-year peak (dry season)\n","train.groupby('month').mean().reset_index().plot(y='burn_area', x='month', kind='bar')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RDCOsUvCz3dA","colab_type":"text"},"source":["# **5. Features selection**\n"]},{"cell_type":"code","metadata":{"id":"oALRZR-w0r3t","colab_type":"code","colab":{}},"source":["# Define input and output columns\n","in_cols = ['climate_aet',\n","       'climate_def', 'climate_pet', 'climate_pr',\n","       'climate_srad',\n","       'climate_tmmn', 'climate_tmmx', 'climate_vap', 'climate_vpd',\n","       'climate_vs', 'elevation', 'landcover_2',\n","       'landcover_4',\n","        'precipitation', 'month']\n","target_col = 'burn_area'\n","in_cols"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCk5CZKI0Kt4","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","sub_features = test[in_cols]\n","features = train[in_cols]\n","labels = train[target_col]\n","\n","start_sub = len(features)\n","features = pd.concat([features, sub_features], axis=0, sort = False)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hnUi-39pQWno","colab_type":"text"},"source":["# **6. Scale data**\n"]},{"cell_type":"code","metadata":{"id":"1T8rQ4HK9B4r","colab_type":"code","colab":{}},"source":["#scale data\n","def scale(df, cols):     \n","    for col in cols:\n","        df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n","    return df\n","features = scale(features, in_cols)\n","features.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0isx9LCaQciq","colab_type":"text"},"source":["# **7. Encode data**\n"]},{"cell_type":"code","metadata":{"id":"dIO3QyBc8_GT","colab_type":"code","colab":{}},"source":["# Encode string data\n","\n","def oneHotEncode(df, col):\n","    df[col] = pd.Categorical(df[col])\n","    dfDummies = pd.get_dummies(df[col], prefix = col)\n","    df = pd.concat([df, dfDummies], axis=1)\n","    df.drop([col], axis = 1, inplace = True)\n","    return df\n","features = oneHotEncode(features, \"month\")\n","\n","\n","test = features[start_sub:]\n","features = features[:start_sub]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WbBususyyP-t","colab_type":"code","colab":{}},"source":["features.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"msS_yI4oQg65","colab_type":"text"},"source":["# **8. Creating and Training the models**\n","\n"]},{"cell_type":"code","metadata":{"id":"4nmztvaEP-F2","colab_type":"code","colab":{}},"source":["from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.svm import SVR\n","areas = [[] for i in range(total_areas)]\n","models = [None for i in range(total_areas)]\n","print(total_areas)\n","# going through each area and create its own model\n","for i in range(total_areas):\n","  print((i + 1) / total_areas * 100 , \"%\")\n","  j = i\n","  while (j < len(train)):\n","    areas[i].append(j)\n","    j += total_areas\n","\n","  small_feat = features.loc[areas[i]]\n","  small_labs = labels[areas[i]]\n","  models[i] = RandomForestRegressor()\n","  models[i].fit(small_feat, small_labs)\n","  \n","  \n","print(areas[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XTcTle4DQlyY","colab_type":"text"},"source":["# **9. Make the preditions**\n"]},{"cell_type":"code","metadata":{"id":"OLs1R2A_XCMb","colab_type":"code","colab":{}},"source":["# make the prediction for the test file and save the results\n","areas_sub = [[] for i in range(total_areas)]\n","preds = [0] * len(test)\n","for i in range(total_areas):\n","  print((i + 1) / total_areas * 100 , \"%\")\n","  j = i\n","  while (j < len(test)):\n","    areas_sub[i].append(j)\n","    j += total_areas\n","\n","  small_feat = test.loc[areas_sub[i]]\n","  \n","  pred = models[i].predict(small_feat)\n","\n","  j = i\n","  cp = 0\n","  while (j < len(test)):\n","    preds[j] = pred[cp]\n","    cp += 1\n","    j += total_areas\n","  \n","  \n","print(areas[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l6fL-N7UQ5RX","colab_type":"text"},"source":["# **10. Make the output file**\n"]},{"cell_type":"code","metadata":{"id":"g1R6b81-cMtz","colab_type":"code","colab":{}},"source":["# create the submission file\n","ss = pd.read_csv('UmojaHack#3:Hotspots/SampleSubmission.csv')\n","ss['Prediction'] = preds\n","ss.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNx7nXhWeBtT","colab_type":"code","colab":{}},"source":["\n","ss.to_csv('starter_submission_16.csv', index=False)"],"execution_count":0,"outputs":[]}]}